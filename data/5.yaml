properties:

  id: 5
  title: What We Learned from the Recent Mandrill Outage
  organization: Mailchimp
  product: Mandrill
  start_ts: 2019/02/04
  end_ts: 2019/02/05
  author: Eric Muntz (SVP of Technology)
  url: https://mailchimp.com/what-we-learned-from-the-recent-mandrill-outage/
  technologies: PostgreSQL
  
  quote: In November of 2018, engineers on our Mandrill team identified the potential to reach wraparound, as the XIDs were climbing to approximately half their total limit during peak load. Our team determined wraparound was not an immediate threat, but we added a ticket to the backlog to set up additional monitoring.
  
  architecture: Job processing application using several PostgreSQL databases as a shared key-value store that is sharded by key. [12]

  root cause: The sharding algorithm caused one database to have higher than normal writes and the autovacuuming process failed or fell behind. [12,13]

  failure: The databases went into safety shutdown mode leading to failed database writes. [13]

  impact: 20% of jobs were delayed. [3,24]

  how it happened: Due to higher than normal traffic to one database (ie, one shard) the autovacuuming process failed or fell behind, and so the database went into safety shutdown mode to prevent transaction id wraparound. Jobs failed and were queued on the application servers causing disk space to run low. [12,13,14,15]
  
  mitigation: Dumped and restored the database while the vacuum process was in progress, leaving out non-essential data tables to speed up process. [22]
